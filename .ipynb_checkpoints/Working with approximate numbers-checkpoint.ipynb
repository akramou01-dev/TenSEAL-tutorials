{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b17dbc5",
   "metadata": {},
   "source": [
    "In this netbook we will work on the encryption of the real numbers, we will also study another case of encrypted evaluation on convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2629c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from random import randint\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8201c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_scale = 40\n",
    "poly_mod_degree = 8192\n",
    "coeff_mod_bit_sizes = [60,bit_scale,bit_scale,60] # 4primes are generated of sizes : 60bits, 40bits, 40bits and 60bits\"\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS,poly_mod_degree,coeff_mod_bit_sizes = coeff_mod_bit_sizes)\n",
    "context.global_scale = 2**bit_scale\n",
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8a239",
   "metadata": {},
   "source": [
    "## Using the plain tensor Class \n",
    "\n",
    "\n",
    "The PlainTensor class is the translation layer form a common tensor representation to the encrypted tensor offred by TenSEAL .\n",
    "\n",
    "for creating a plain tensor we must give the .plain_tensor() method the data and the shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7597c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 4.0], [6.0, 9.0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plain_tensor = ts.plain_tensor(np.array([1,4,6,9]).reshape(2,2))\n",
    "print(plain_tensor.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c9acb",
   "metadata": {},
   "source": [
    "before the encryption of new message, The CKKS requires two operation:\n",
    "\n",
    "    Encoding and decoding : \n",
    "        it encode a vector of real/complexe number into a plain tensor polynomial to be encrypted and computed \n",
    "        the encoding operation converts vector of poly_mod_degree/2 elements into plaintext elements, HE operation are \n",
    "            performed on such encrypted vector\n",
    "        for the encoding operation we need to multiply the vector by the scaling factor \n",
    "       \n",
    "        The encoding operation transform a message vector to a plain tensor polynomial (encoded message)\n",
    "        \n",
    "\n",
    "\n",
    "So for encrypting a vector message we need first to encode it using the encoding operation to a polynomial plain tensor and after that we encrypt the plain tensor to a cipher text\n",
    "        \n",
    "        \n",
    "* Note : an encryption of message m is not decrypted of exactly m but m + e where e is some error  \n",
    "\n",
    "The encoding and encryption operations are done automaticly by TenSEAL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06a16522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "plain1 = ts.plain_tensor([25,4,1999])\n",
    "plain2 = ts.plain_tensor([21,6,1999])\n",
    "enc_tensor1 = ts.ckks_tensor(context,plain1)\n",
    "enc_tensor2 = ts.ckks_tensor(context,plain2)\n",
    "print(enc_tensor1.shape)\n",
    "print(enc_tensor2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77689e",
   "metadata": {},
   "source": [
    "## Basic operations\n",
    "\n",
    "The following table enumerates the operations supported by CKKS tensors variants.\n",
    "\n",
    "| Operation                    | Description                                                   |\n",
    "| --- | --- |\n",
    "| negate                       | Negate an encrypted tensor                                    |\n",
    "| square                       | Compute the square of an encrypted tensor                     |\n",
    "| power                        | Compute the power of an encrypted tensor                      |\n",
    "| add                          | Addition between two encrypted tensors                        |\n",
    "| add\\_plain                   | Addition between an encrypted tensor and a plain tensor       |\n",
    "| sub                          | Subtraction between two encrypted tensors                     |\n",
    "| sub\\_plain                   | Subtraction between an encrypted tensor and a plain tensor    |\n",
    "| mul                          | Multiplication between two encrypted tensors                  |\n",
    "| mul\\_plain                   | Multiplication between an encrypted tensor and a plain tensor |\n",
    "| dot                 | Dot product between two encrypted tensors                     |\n",
    "| dot\\_plain          | Dot product between an encrypted tensor and a plain tensor    |\n",
    "| polyval                      | Polynomial evaluation with an encrypted tensor as variable    |\n",
    "| matmul                | Multiplication between an encrypted vector and a plain matrix |\n",
    "| matmul\\_plain           | Encrypted matrix multiplication with plain vector             |\n",
    "\n",
    "\n",
    "The CKKSVector variant contains the following additional operations:\n",
    "\n",
    "\n",
    "| Operation                    | Description                                                   |\n",
    "| --- | --- |\n",
    "| conv2d\\_im2col               | Image Block to Columns                                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fdd39a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "plain1 = ts.plain_tensor(np.array([25,4,1999]))\n",
    "plain2 = ts.plain_tensor(np.array([21,6,1999]))\n",
    "enc_tensor1 = ts.ckks_tensor(context,plain1)\n",
    "enc_tensor2 = ts.ckks_tensor(context,plain2)\n",
    "print(enc_tensor1.shape)\n",
    "print(enc_tensor2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b47bac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected result : [46.0, 10.0, 3998.0]\n",
      "Decrypted result : [45.99999999750704, 9.999999999608518, 3997.9999999975066] \n"
     ]
    }
   ],
   "source": [
    "#addition of 2 encrypted tensors \n",
    "result = enc_tensor1 + enc_tensor2 \n",
    "print(f\"Expected result : {[x + y for x,y in zip(plain1.tolist(), plain2.tolist())]}\")\n",
    "print(f\"Decrypted result : {result.decrypt().tolist()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c3430d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected result : [4.0, -2.0, 0.0]\n",
      "Decrypted result : [3.999999999649789, -1.9999999993117281, 2.710660385260499e-09] \n"
     ]
    }
   ],
   "source": [
    "#sub of 2 encrypted tensors \n",
    "sub_result = enc_tensor1 - enc_tensor2\n",
    "print(f\"Expected result : {[x - y for x,y in zip(plain1.tolist(), plain2.tolist())]}\")\n",
    "print(f\"Decrypted result : {sub_result.decrypt().tolist()} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f76d0",
   "metadata": {},
   "source": [
    "for the multiplication we will apply the relinearization as the folowing :\n",
    "    \n",
    "* we have ct(S) = c0 + c1S \n",
    "    * so ct_mul= ct + ct' = d0 + d1S + d2S4' \n",
    "    * ct_mul --> ct_mul' = d0' + d1S (doing the relinearization operation to reduce the size to 2)\n",
    "    \n",
    "    we see that we changed tha format of the ciphertext (d0',d1') and preserving the encrypted plaintext (S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8abf013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected result : [525.0, 24.0, 3996001.0]\n",
      "Decrypted result : [525.0000703548933, 24.000003214218825, 3996001.535896948] \n"
     ]
    }
   ],
   "source": [
    "#multiplication of 2 encrypted tensors \n",
    "\n",
    "mul_result = enc_tensor1 * enc_tensor2\n",
    "print(f\"Expected result : {[x * y for x,y in zip(plain1.tolist(), plain2.tolist())]}\")\n",
    "print(f\"Decrypted result : {mul_result.decrypt().tolist()} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d96bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The plain tensor: \n",
      "\t[1.0, 2.0, 3.0] \n",
      "The result of the multiplication : \n",
      "\t[25.000003352062517, 8.000001071168708, 5997.000804249581] \n"
     ]
    }
   ],
   "source": [
    "#multiplication with plain tensor \n",
    "plain= ts.plain_tensor([1,2,3])\n",
    "plain_mul_result = enc_tensor1 * plain\n",
    "print(f\"The plain tensor: \\n\\t{plain.tolist()} \\nThe result of the multiplication : \\n\\t{plain_mul_result.decrypt().tolist()} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd7795f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected result = [-25.0, -4.0, -1999.0]\n",
      "Decrypted result : [-24.999999997687816, -3.999999999281675, -1998.999999998592]\n"
     ]
    }
   ],
   "source": [
    "#Negation \n",
    "neg_result = - enc_tensor1\n",
    "print(f\"The expected result = {[-x for x in plain1.tolist()]}\")\n",
    "print(f\"Decrypted result : {neg_result.decrypt().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4e618e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected result = [15625.0, 64.0, 7988005999.0]\n",
      "Decrypted result : [15625.01256850256, 64.00005146124501, -39541.37576575875]\n"
     ]
    }
   ],
   "source": [
    "#Power \n",
    "pow_result = enc_tensor1 **3\n",
    "print(f\"The expected result = {[x**3 for x in plain1.tolist()]}\")\n",
    "print(f\"Decrypted result : {pow_result.decrypt().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af8596d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected result = [16251.0, 81.0, 7992002001.0]\n",
      "Decrypted result : [16251.012652206773, 81.00005360189009, -237842.83986909915]\n"
     ]
    }
   ],
   "source": [
    "# polynomial evaluation 1 + X^2 + X^3\n",
    "poly_result = enc_tensor1.polyval([1,0,1,1])\n",
    "print(f\"The expected result = {[ 1 + x**2 + x**3 for x in plain1.tolist()]}\")\n",
    "print(f\"Decrypted result : {poly_result.decrypt().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57fe0b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected result is : [-57.075, 1.032, -31951629.693]\n",
      "The Decrypted result is : [-57.07505790189241, 1.0319998359379208, -494379.6873013852]\n"
     ]
    }
   ],
   "source": [
    "#Sigmoid approximation  0.5 + 0.197x -0.004x**3\n",
    "sig_result = enc_tensor1.polyval([0.5,0.197,0,-0.004])\n",
    "print(f'The expected result is : {[0.5+ 0.197*x -0.004*x**3 for x in plain1.tolist()]}')\n",
    "print(f\"The Decrypted result is : {sig_result.decrypt().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab14800",
   "metadata": {},
   "source": [
    "Wee see that as we increase the number (result is bigger) as the error is increasing , and this is the noise growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2ab6a",
   "metadata": {},
   "source": [
    "## Encrypted Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad7954",
   "metadata": {},
   "source": [
    "we will work on classification on the MNIST Dataset using one conv and 2 fully connected layers and a square fonction as an activation fonction \n",
    "\n",
    "in the next exemple we will use a demo for the eeval method explained here : https://github.com/youben11/encrypted-evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e712093",
   "metadata": {},
   "source": [
    "so , we will study the use case that a client has a data and he want to evalute it in an encrypted model which is hosted is a server, for that we need 2 parties : \n",
    "   \n",
    "* Client Side : the client will encrypt the model input and send them to the server \n",
    "* Server side : contains one or multiple models hosted  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da442ac",
   "metadata": {},
   "source": [
    "### Client Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7428123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the TenSEAL context\n",
    "bit_scale = 21\n",
    "coeff_mod_bit_sizes = [40,bit_scale,bit_scale,bit_scale,bit_scale,bit_scale,bit_scale,40]\n",
    "poly_mod_degree = 8192\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS,poly_mod_degree,coeff_mod_bit_sizes=coeff_mod_bit_sizes)\n",
    "context.global_scale = 2**bit_scale\n",
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "297d3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper fonction for loading one image from the dataset \n",
    "def load_input():\n",
    "    transform = transforms.Compose(\n",
    "    #the input should be normalized by a mean of 0.1307 and a std of 0.3081\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "    \n",
    "    idx = randint(1, 5)\n",
    "    img_name = \"data/mnist-samples/img_{}.jpg\".format(idx)\n",
    "    print(img_name)\n",
    "    img = Image.open(img_name)\n",
    "\n",
    "    # the input also should be a matrix of 28x28 representing the image\n",
    "    # we will return also the original image for checking the results returned by the model hosted in the server \n",
    "    return transform(img).view(28, 28).tolist(), img\n",
    "# another helper fonction to encrypt the image \n",
    "def prepare_input(context,plain_input): \n",
    "    # the .im2col_encoding() encode an image into a CKKSVector , it has 5 params \n",
    "        # Context for encrypting the data \n",
    "        # the plain tensor \n",
    "        # kernal_n_rows: number of rows used in the kernel of  the Conv2d\n",
    "        # kernel_n_cols: number of cols used in the kernel of the conv2d \n",
    "        # stride : stride that will be used in the conv2d\n",
    "    enc_img,windows_nb = ts.im2col_encoding(context,plain_input,kernel_n_rows= 7 , kernel_n_cols=7,stride = 3)\n",
    "    print(windows_nb)\n",
    "    assert windows_nb == 64\n",
    "    return enc_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9897d129",
   "metadata": {},
   "source": [
    "the 2 helper fonctions we will need them before sending the data to the server where the model is hosted \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64e70e",
   "metadata": {},
   "source": [
    "### Server side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ec31442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model hosted in the server \n",
    "\n",
    "class ConvMNIST(): \n",
    "    def __init__(self,parameters: Dict[str,list]): \n",
    "        self.conv_weight = parameters[\"conv1_weight\"]\n",
    "        self.conv_bias = parameters[\"conv1_bias\"]\n",
    "        self.fc1_weight = parameters[\"fc1_weight\"]\n",
    "        self.fc1_bias = parameters[\"fc1_bias\"]\n",
    "        self.fc2_weight = parameters[\"fc2_weight\"]\n",
    "        self.fc2_bias = parameters[\"fc2_bias\"]\n",
    "        self.windows_nb = parameters[\"windows_nb\"]     \n",
    "#         self.windows_nb = 72      \n",
    "    def forward(self,enc_x):\n",
    "        channels = []\n",
    "        # each itteration of the for loop below is a multiplication of the kernel and a matrix of 7 x 7 (channel * kernel) \n",
    "        # the result of the multiplication is stored in the channels array \n",
    "        # after each itteration we stride by 3 to move to the next channel\n",
    "        for kernel , bias in zip(self.conv_weight,self.conv_bias): \n",
    "            y = enc_x.conv2d_im2col(kernel,self.windows_nb) + bias\n",
    "            channels.append(y)\n",
    "        \n",
    "        \n",
    "        # here we are some kind of flatten the channels into on vector for giving them to other linear layers \n",
    "        out = ts.CKKSVector.pack_vectors(channels)\n",
    "        \n",
    "        print(out)\n",
    "        #doing the first square fonction (activation fonction)\n",
    "        out.square_()\n",
    "        \n",
    "        # .mm_() fonction is multiply matrix\n",
    "        out = out.mm_(self.fc1_weight) + self.fc1_bias\n",
    "        \n",
    "        out.square_()\n",
    "        \n",
    "        out = out.mm_(self.fc2_weight)+ self.fc2_bias\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # now we will create a helper fonction to deserialize the context and the model input which we get from the client \n",
    "    # note that the context and the input are serializable by the client before sending them to the server \n",
    "    @staticmethod \n",
    "    def prepare_input(context,ckks_vector): \n",
    "        try: \n",
    "            ctx = ts.context_from(context)\n",
    "            #linking the enc vector with the contexte\n",
    "            enc_x = ts.ckks_vector_from(ctx,ckks_vector)\n",
    "        except:\n",
    "            raise DeserializationError(\"cannot deserialize context or ckks_vector\")\n",
    "\n",
    "        try:\n",
    "            # checking the galois keys in the serializable context\n",
    "            _ = ctx.galois_keys()\n",
    "        except: \n",
    "            raise InvalidContext(\"the context doesn't hold galois keys\")\n",
    "        return enc_x\n",
    "    \n",
    "    def __call__(self,*args,**keys): \n",
    "        return self.forward(*args,**keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e4874",
   "metadata": {},
   "source": [
    "Now we will define some helper fonctions in the server side  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4a4e8753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 'parameters/ConvMNIST-0.1.pickle'\n"
     ]
    }
   ],
   "source": [
    "# Loading the model parameters \n",
    "import os \n",
    "import pickle \n",
    "def load_params(file_path): \n",
    "    try:\n",
    "        parameters = pickle.load(open(file_path, \"rb\"))\n",
    "        print(f\"Model loaded from '{file_path}'\")\n",
    "    except OSError as ose:\n",
    "        print(\"error\", ose)\n",
    "        raise ose\n",
    "    return parameters \n",
    "\n",
    "parameters = load_params(\"parameters/ConvMNIST-0.1.pickle\")\n",
    "model = ConvMNIST(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec46673",
   "metadata": {},
   "source": [
    "### Client Query "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febf477",
   "metadata": {},
   "source": [
    "The client has to create the context for the first query, and choose a sample image from the dataset.\n",
    "\n",
    "The serialized context and the encrypted image are sent to the model in the server for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "e62b5d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/mnist-samples/img_1.jpg\n",
      "64\n",
      "Encrypted image is  : <tenseal.tensors.ckksvector.CKKSVector object at 0x000001A48D6598B0>\n",
      "Originale image is : \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating the Ckks context\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree,coeff_mod_bit_sizes = coeff_mod_bit_sizes)\n",
    "context.global_scale= 2**bit_scale\n",
    "context.generate_galois_keys()\n",
    "# choose a random image from the dataset \n",
    "image , original_image = load_input()\n",
    "\n",
    "# image encryption\n",
    "\n",
    "\n",
    "enc_image= prepare_input(context,image)\n",
    "\n",
    "print(f\"Encrypted image is  : {enc_image}\")\n",
    "print(f\"Originale image is : \")\n",
    "imshow(original_image)\n",
    "\n",
    "#preparing the context for the server \n",
    "server_context = context.copy()\n",
    "#we are not saving the secret key because we are doing a copy for the context ! \n",
    "\n",
    "server_context.make_context_public()\n",
    "\n",
    "server_context = server_context.serialize()\n",
    "enc_image = enc_image.serialize()\n",
    "\n",
    "client_query = {\n",
    "    \"data\": enc_image,\n",
    "    \"context\" : server_context\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84dd2a3",
   "metadata": {},
   "source": [
    "### Server deeling with the client query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cda878dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tenseal.tensors.ckksvector.CKKSVector object at 0x000001A48D11D1C0>\n"
     ]
    }
   ],
   "source": [
    "# The server inference \n",
    "\n",
    "encrypted_query = model.prepare_input(client_query[\"context\"],client_query[\"data\"])\n",
    "# we do the evaluation of the encrypted data and we serialize the results before sending it to the client\n",
    "encrypted_result = model(encrypted_query).serialize()\n",
    "\n",
    "encrypted_response = {\n",
    "    \"data\": encrypted_result\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59c0f5",
   "metadata": {},
   "source": [
    "### client process the response of the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "1b2b6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum probability for label 1\n"
     ]
    }
   ],
   "source": [
    "result = ts.ckks_vector_from(context,encrypted_response[\"data\"]).decrypt()\n",
    "\n",
    "probs = torch.softmax(torch.tensor(result),0)\n",
    "label_max = torch.max(probs)\n",
    "print(f\"Maximum probability for label {int(label_max)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5c156",
   "metadata": {},
   "source": [
    "## Finaly , we was able to simulate a used case for encrypted evaluation on encrypted model hosted on a server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54913838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
