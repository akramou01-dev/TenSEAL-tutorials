{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f1d458",
   "metadata": {},
   "source": [
    "# Encrypted Convolution on MNIST \n",
    "\n",
    "In this notebook we perform encrypted eval on MNIST Dataset, and for this we will use a single Neural Network compose of 1 Convulution layer and another 2 linear layers, for simplicity we are using the square fonction as an activation fonction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83af3c1",
   "metadata": {},
   "source": [
    "## Model Description\n",
    "The model is the sequence of the below layers:\n",
    "\n",
    "- **Conv:** Convolution with 4 kernels. Shape of the kernel is 7x7. Strides are 3x3.\n",
    "- **Activation:** Square activation function.\n",
    "- **Linear Layer 1:** Input size: 256. Output size: 64.\n",
    "- **Activation:** Square activation function.\n",
    "- **Linear Layer 2:** Input size: 64. Output size: 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e42a6",
   "metadata": {},
   "source": [
    "### Convolution \n",
    "\n",
    "for the convolution operation we will use the algo that translate the 2D conv into a single matrix multiplication and \n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"assets/im2col_conv2d.png\" width=\"50%\"/>\n",
    "<div><b>Figure1:</b> Image to column convolution</div>\n",
    "</div>\n",
    "\n",
    "**The figure is taken from the official TenSEAL Tutorials**\n",
    "\n",
    "this operation requires arranging the elements of the matrix , and since we can't do that with the ciphertext so we will do a pre-processing before the encryption step.we first need to apply an *im2col* operation to the input matrix and encrypt it into a single ciphertext( we translate it into a single vecor using a vertical scan), then we do a matrix multiplication between the encrypted matrix  and the flattened kernel vector which replicate every element **n** times where **n** is the number of windows .then we do a ciphertext-plaintext multiplication witch a sequence of rotate and sum operations in order to sum the elements of a single window \n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"assets/im2col_conv2d_ckks1.png\" width=\"50%\"/>\n",
    "<div><b>Figure2:</b> Image to column convolution with CKKS - step 1</div>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"assets/im2col_conv2d_ckks2.png\" width=\"50%\"/>\n",
    "<div><b>Figure3:</b> Image to column convolution with CKKS - step 2</div>\n",
    "</div>\n",
    "\n",
    "if we have multiple kernels so we need to do this operation multiple times and combines the results in a single vector which will be the input of the linear layer\n",
    "\n",
    "\n",
    "### Linear Layer \n",
    "for the linear layer we will multiply the vector by the plain matrix and adding the plain bias, the multiplication is used based on the method explained in the figure below : \n",
    "<div align=\"center\">\n",
    "<img src=\"assets/vec-matmul.png\" width=\"65%\"/>\n",
    "<div><b>Figure4:</b> Vector-Matrix Multiplication</div>\n",
    "</div>\n",
    "\n",
    "### Square fonction\n",
    "the square fonction is very simple we need just to multiply the vector by itself \n",
    "\n",
    "after explaining each operation we conclude that we need 6 multiplications : 2 for the convolutions, 1 for the first square fonction , 1 for the first linear layer , 1 for the second square fonctions , 1 for the second linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777306a3",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n",
    "now that we know how these operations work in theory we will implement a model of HE using the TenSEAL lib, but first we need to implement a Pytorch Model to classify the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f9ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2d646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d868049f79f478892bcb46eb78fc9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d000f80cc5c4b05b4bfbda555c65c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0762a48d8e7a436bba76f65868f542b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8d828c6dff424785965c108dc50edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\21355\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets \n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np \n",
    "\n",
    "train_data = datasets.MNIST('data',train=True,download =True,transform = transforms.ToTensor())\n",
    "test_data = datasets.MNIST('data',train=False,download=True,transform = transforms.ToTensor())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8c77959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dl = DataLoader(train_data,batch_size = batch_size,shuffle = True)\n",
    "test_dl = DataLoader(test_data,batch_size= 1,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa23698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.440560\n",
      "Epoch: 2 \tTraining Loss: 0.154996\n",
      "Epoch: 3 \tTraining Loss: 0.107849\n",
      "Epoch: 4 \tTraining Loss: 0.083934\n",
      "Epoch: 5 \tTraining Loss: 0.068531\n",
      "Epoch: 6 \tTraining Loss: 0.058931\n",
      "Epoch: 7 \tTraining Loss: 0.051740\n",
      "Epoch: 8 \tTraining Loss: 0.046910\n",
      "Epoch: 9 \tTraining Loss: 0.041639\n",
      "Epoch: 10 \tTraining Loss: 0.037754\n"
     ]
    }
   ],
   "source": [
    "# the output of the conv2d layer will be 4 vecctors each vector contains 64 slots(because we have 64 windows 1 value for each window)\n",
    "class ConvMnist(torch.nn.Module):\n",
    "    def __init__(self, hidden=64, output=10):\n",
    "        super(ConvMnist, self).__init__()        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 4, kernel_size=7, padding=0, stride=3)\n",
    "        self.fc1 = torch.nn.Linear(256, hidden)\n",
    "        self.fc2 = torch.nn.Linear(hidden, output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # the model uses the square activation function\n",
    "        x = x * x\n",
    "        # flattening while keeping the batch axis\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc1(x)\n",
    "        x = x * x\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, n_epochs=10):\n",
    "    # model in training mode\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "\n",
    "        train_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "    \n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = ConvMnist()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model = train(model, train_dl, criterion, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e469242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.08376144944224506\n",
      "Class Correct : [966.0, 1124.0, 1010.0, 988.0, 963.0, 851.0, 951.0, 999.0, 957.0, 989.0]\n",
      "Class total : [980.0, 1135.0, 1032.0, 1010.0, 982.0, 892.0, 958.0, 1028.0, 974.0, 1009.0]\n",
      "Test Accuracy of 0: 98% (966/980)\n",
      "Test Accuracy of 1: 99% (1124/1135)\n",
      "Test Accuracy of 2: 97% (1010/1032)\n",
      "Test Accuracy of 3: 97% (988/1010)\n",
      "Test Accuracy of 4: 98% (963/982)\n",
      "Test Accuracy of 5: 95% (851/892)\n",
      "Test Accuracy of 6: 99% (951/958)\n",
      "Test Accuracy of 7: 97% (999/1028)\n",
      "Test Accuracy of 8: 98% (957/974)\n",
      "Test Accuracy of 9: 98% (989/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9798/10000)\n"
     ]
    }
   ],
   "source": [
    "def test(model,test_dl, criterion): \n",
    "    test_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total =list(0. for i in range(10)) \n",
    "    for data,target in test_dl: \n",
    "        output = model(data)\n",
    "        loss = criterion(output,target)\n",
    "        test_loss+=loss.item()\n",
    "        \n",
    "        # transform output probas to predicted class using torch.max() fonction which returns 2 results (when dim=1) : \n",
    "            # first an array with the max value of each row (the max prob in every sample class)\n",
    "            # second an array that contains the indexes of the max proba in each row\n",
    "        _,preds = torch.max(output,dim=1)\n",
    "        # preds example = [3,5,0,1,4,5,6...]\n",
    "        #compare the predictions to the true labels \n",
    "        correct = np.squeeze(preds.eq(target.data.view_as(preds)))\n",
    "        # calculate the correct labels for each object \n",
    "        for i in range(len(target)):\n",
    "            # in this loop we are going to count the number of correct prediction for avery class  \n",
    "            label = target.data[i]\n",
    "            # adding +1 to the label if the prediction is correct else adding 0 in the list defined first \n",
    "            # we add 1 to the class_correct[label] if the predictions is true(check it in the correct array) else add 0\n",
    "            class_correct[label] += correct[i].item()\n",
    "            # increment the class_total[lable] (of each label) by 1\n",
    "            class_total[label] +=1\n",
    "            \n",
    "        # calculate the avg loss test \n",
    "    test_loss /= len(target)\n",
    "    print(f\"Test loss : {test_loss}\")\n",
    "        \n",
    "    print(f\"Class Correct : {class_correct}\")\n",
    "    print(f\"Class total : {class_total}\")\n",
    "    for label in range(10):\n",
    "        print(f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
    "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})')\n",
    "\n",
    "    print(f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ' \n",
    "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
    "    )\n",
    "    \n",
    "            \n",
    "        \n",
    "test(model,test_dl,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a23bc841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0807, -0.0213,  0.0576,  0.1030,  0.1820,  0.0284,  0.0028,  0.0861,\n",
       "         0.0578,  0.0746,  0.0697,  0.1778,  0.1499,  0.0184,  0.0172, -0.0491,\n",
       "         0.0099, -0.0215,  0.1208,  0.2982,  0.1099, -0.1379, -0.0627, -0.0542,\n",
       "        -0.0041,  0.1026,  0.1210, -0.0228, -0.1597, -0.0300,  0.0080, -0.0396,\n",
       "        -0.2043, -0.0416, -0.1052, -0.0073,  0.0518,  0.0599, -0.0298,  0.0446,\n",
       "         0.0085, -0.0113, -0.0093,  0.1461,  0.1221, -0.0651, -0.1133, -0.0393,\n",
       "         0.0285, -0.0013, -0.0018,  0.0656,  0.0571,  0.0017, -0.0691,  0.0640,\n",
       "         0.0309,  0.0613,  0.0098,  0.0322,  0.0356,  0.0670, -0.0452,  0.0909,\n",
       "         0.1450,  0.1128,  0.1454,  0.0751, -0.0691,  0.0815,  0.1116, -0.0008,\n",
       "         0.0635,  0.1084,  0.0704, -0.1360, -0.1425,  0.0592,  0.1031,  0.1103,\n",
       "         0.0977, -0.0357, -0.0940, -0.1817, -0.1355,  0.0654,  0.1192,  0.0740,\n",
       "         0.0528, -0.0117,  0.0386, -0.1803, -0.0601,  0.0439,  0.0805,  0.0361,\n",
       "         0.0210, -0.0138, -0.1610, -0.1562,  0.1192,  0.1218, -0.1328, -0.0590,\n",
       "         0.2232,  0.0593, -0.2317, -0.1076,  0.0901,  0.0213,  0.0189, -0.0360,\n",
       "        -0.0344,  0.0285,  0.0050, -0.0469,  0.0447,  0.0957,  0.0694,  0.0054,\n",
       "         0.0415,  0.0079, -0.0694, -0.1222,  0.1073,  0.0131,  0.0252, -0.0298,\n",
       "         0.2629,  0.1230,  0.1519,  0.0831,  0.0411,  0.1366,  0.0230,  0.1762,\n",
       "         0.1457,  0.0941,  0.1501,  0.0218, -0.0068,  0.0982,  0.1180, -0.0418,\n",
       "        -0.1277, -0.0933, -0.2191, -0.1774,  0.0669,  0.0711,  0.1219, -0.2353,\n",
       "        -0.2186, -0.2357, -0.1908, -0.0651, -0.0616, -0.0918, -0.0794, -0.1894,\n",
       "         0.0658, -0.2456, -0.1238, -0.0680,  0.1305, -0.0833,  0.0126, -0.0621,\n",
       "         0.1218,  0.0268, -0.1026, -0.0214,  0.0833,  0.0060, -0.1106, -0.0057,\n",
       "         0.1378,  0.0636, -0.0326, -0.0435,  0.0377,  0.0459, -0.0481,  0.0992,\n",
       "        -0.0461,  0.1876, -0.0387,  0.0285,  0.0705,  0.0408,  0.0339, -0.0267,\n",
       "         0.2680,  0.1386,  0.1563,  0.0800,  0.0251,  0.0633, -0.0824, -0.1354,\n",
       "         0.2312, -0.0729,  0.0273, -0.0047, -0.0463, -0.0609, -0.0385, -0.1220,\n",
       "         0.0693,  0.0435,  0.0780,  0.1356,  0.0462,  0.0300,  0.0603,  0.1517,\n",
       "        -0.0831, -0.0481,  0.0195,  0.0903,  0.1583,  0.1704,  0.1280,  0.0515,\n",
       "        -0.0888,  0.0185,  0.0412,  0.0266,  0.1037,  0.0429, -0.1744, -0.0523,\n",
       "        -0.0200, -0.0699, -0.0659, -0.0240, -0.0431,  0.0484, -0.0849, -0.1314,\n",
       "        -0.0104,  0.1437, -0.0683,  0.0554, -0.0955,  0.0166,  0.0632,  0.0460,\n",
       "         0.2048, -0.0109,  0.1201,  0.0443,  0.0243,  0.0085, -0.0852, -0.0569])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e328e40",
   "metadata": {},
   "source": [
    "## Encrypted eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "69106509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "106167ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will evaluate encrypted data on HE Conv NN\n",
    "class HEConvMNIST: \n",
    "    def __init__(self,model): \n",
    "        #extracting the weight and bias of the convolution layer\n",
    "        # we are using the .view() method for the reshaping the weight into 4 groups of 7x7 matrix and for not hardcoding it \n",
    "        self.conv_weight = model.conv1.weight.data.view(\n",
    "        model.conv1.out_channels , model.conv1.kernel_size[0], model.conv1.kernel_size[1]\n",
    "        )\n",
    "        self.conv_bias = model.conv1.bias.data.tolist()\n",
    "        #extracting the first linear layer \n",
    "        self.lin1_weight = model.fc1.weight.T.data.tolist()\n",
    "        self.lin1_bias = model.fc1.bias.data.tolist()\n",
    "        \n",
    "        #extracting the second linear layer\n",
    "        self.lin2_weight = model.fc2.weight.T.data.tolist()\n",
    "        self.lin2_bias =model.fc2.bias.data.tolist()\n",
    "        \n",
    "    def forward(self,enc_x,windows_nb): \n",
    "        #windows_nb is the number of the windows in the convolution and we are using it when applying the convolution in the .conv2d_im2col() method\n",
    "        enc_channels = [] #this list is for saving the result of the conv of each channel \n",
    "        for kernel , bias in zip(self.conv_weight,self.conv_bias): \n",
    "            #applying the convolution for every kernel\n",
    "            # we can apply the .conv2d_im2col() method on the enc_x input because we are doing pre-preocessing to the data before giving them to the model\n",
    "            y = enc_x.conv2d_im2col(kernel,windows_nb) + bias \n",
    "            enc_channels.append(y)\n",
    "            \n",
    "        # pack all the channels into a single flattened vector \n",
    "        enc_x = ts.CKKSVector.pack_vectors(enc_channels)\n",
    "        \n",
    "        #applying the square fonction\n",
    "        enc_x.square_()\n",
    "        \n",
    "        #first linear layer \n",
    "        enc_x = enc_x.mm(self.lin1_weight) +self.lin1_bias\n",
    "\n",
    "        # square fonction 2nd time\n",
    "        enc_x.square_()\n",
    "        \n",
    "        #second linear layer \n",
    "        enc_x = enc_x.mm(self.lin2_weight) + self.lin2_bias\n",
    "        \n",
    "        return enc_x\n",
    "    def __call__(self,*args,**keys):\n",
    "        return self.forward(*args,**keys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6ff0f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3cf8445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_test(context,he_model,test_dl,criterion, kernel_shape,stride): \n",
    "    test_loss = 0.\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    # the class_correct is for counting how much correct prediction for each class (0,1,2,3,...,9)\n",
    "    # the class_total is for counting how much value we have for each class \n",
    "    start_time = time()\n",
    "\n",
    "    for data , target in test_dl:\n",
    "        # first we have to pre-process the data before giving it to the he_model \n",
    "        # for that we need to encrypt the input matrix and extract the windows_nb using the .im2col_encoding()  method\n",
    "        # .im2col_encoding() takes 5 argument \n",
    "            # context for encrypting the data \n",
    "            # the tensor to encrypt\n",
    "            # the kernel_n_rows  \n",
    "            # the kernel_n_cols \n",
    "            # and the stride \n",
    "            # the last 3 args are for doing the convolution in the he model\n",
    "        \n",
    "        enc_x , window_nb = ts.im2col_encoding(context,data.view(28,28).tolist(),kernel_shape[0],kernel_shape[1],stride)\n",
    "        #.view(28,28) is for reshaping the input to a matrix of 28 x 28\n",
    "        enc_output = he_model(enc_x,window_nb)\n",
    "        \n",
    "        output = enc_output.decrypt()\n",
    "        output = torch.tensor(output).view(1,-1)\n",
    "        \n",
    "        #Compute the loss \n",
    "        loss = criterion(output,target)\n",
    "        \n",
    "        #computing the correct labels \n",
    "        test_loss += loss \n",
    "        \n",
    "        #converting the output into predictions \n",
    "        _,preds = torch.max(output,dim=1)\n",
    "        # the preds array will contains the indexes of the values that has max proba in each predction\n",
    "        correct = np.squeeze(preds.eq(target.data.view_as(preds)))\n",
    "        \n",
    "        #calculating the accuracy for each class \n",
    "        label = target[0]\n",
    "        class_correct[label] = correct.item()\n",
    "        class_total[label] +=1\n",
    "\n",
    "    # calculate and print avg test loss\n",
    "    test_loss = test_loss / sum(class_total)\n",
    "    print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "    end_time = time()\n",
    "    for label in range(10):\n",
    "        print(\n",
    "            f'Test Accuracy of {label}: {int(100 * class_correct[label] / class_total[label])}% '\n",
    "            f'({int(np.sum(class_correct[label]))}/{int(np.sum(class_total[label]))})'\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f'\\nTest Accuracy (Overall): {int(100 * np.sum(class_correct) / np.sum(class_total))}% ' \n",
    "        f'({int(np.sum(class_correct))}/{int(np.sum(class_total))})'\n",
    "    )\n",
    "    print(f\"The test operation takes : {round(end_time - start_time,2)} Seconds\")\n",
    "\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2b6ff0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shape = model.conv1.kernel_size\n",
    "stride = model.conv1.stride[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d1be5",
   "metadata": {},
   "source": [
    "### Choosing the parameters\n",
    "\n",
    "Starting with a scale of more than 20 bits, we need to choose the number of bits of all the middle primes equal to that, so we are already over 120 bits. With this lower bound of coefficient modulus and a security level of 128-bits, we will need a polynomial modulus degree of at least 8192. The upper bound for choosing a higher degree is at 218. Trying different values for the precision and adjusting the coefficient modulus, while studying the loss and accuracy, we end up with 26-bits of scale and primes. We also have 5 bits (31 - 26) for the integer part in the last coefficient modulus, which should be enough for our use case, since output values aren't that big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "99df455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encryption params \n",
    "\n",
    "#controle the precision of the fractionnal part \n",
    "bit_scale = 26\n",
    "\n",
    "coeff_mod_bit_sizes = [31,bit_scale,bit_scale,bit_scale,bit_scale,bit_scale,bit_scale,31]\n",
    "poly_mod_degree= 8192\n",
    "\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS,poly_mod_degree,coeff_mod_bit_sizes=coeff_mod_bit_sizes)\n",
    "\n",
    "context.global_scale = 2**bit_scale\n",
    "\n",
    "context.generate_galois_keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c566d46",
   "metadata": {},
   "source": [
    "executing the test over 1000 samples of the MNIST dataset will take time, but we can way that it deserved because we complete an end-to-end Encrypted Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "b5bfd4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16384 // 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_model = HEConvMNIST(model)\n",
    "enc_test(context,he_model,test_dl,criterion,kernel_shape,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3306aebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for x,y in test_dl : \n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935a1c6",
   "metadata": {},
   "source": [
    "In a real-world use case, this would also require sending the encrypted input from the client to the server, and the encrypted result from the server to the client, so the size of these objects really matters. The encrypted input takes about 476KB, while the encrypted result is only about 70KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d2a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
