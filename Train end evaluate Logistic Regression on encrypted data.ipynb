{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edc9e16",
   "metadata": {},
   "source": [
    "# Training and Evaluating Logistic Regression Model on Encrypted data \n",
    "\n",
    "in this notebook we are going to use Homomorphic Encryption to encrypt data before giving it to the LR model for evaluation, and for this we are going to use the HE Lib TenSEAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d14e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "import tenseal as ts \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import secrets\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20173a8",
   "metadata": {},
   "source": [
    "we are going to use the **heart disease prediction** from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31f4a81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(x,y,test_ratio=0.3):\n",
    "    indx = [i for i in range(len(x))]\n",
    "    random.shuffle(indx)\n",
    "    test_size = int(len(x) * test_ratio) \n",
    "    test_indices, train_indices = indx[:test_size] ,indx[test_size:]\n",
    "    return x[train_indices], y[train_indices], x[test_indices],y[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9094c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 4, 1, 56, 3, 5, 6, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test  = split_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422ae72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(128 * 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3373ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./data/framingham.csv\")\n",
    "# drop all the rows that contains nan values\n",
    "dataset = dataset.dropna()\n",
    "# drop some useless features\n",
    "dataset = dataset.drop([\"education\",\"currentSmoker\", \"BPMeds\", \"diabetes\", \"diaBP\", \"BMI\"],axis=1)\n",
    "#groupe the data by TenYearCHD \n",
    "grouped = dataset.groupby('TenYearCHD')\n",
    "dataset = grouped.apply(lambda x: x.sample(grouped.size().min(), random_state=73).reset_index(drop=True))\n",
    "y = th.tensor(dataset[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "dataset = dataset.drop(\"TenYearCHD\",axis=1)\n",
    "dataset = (dataset - dataset.mean())/dataset.std()\n",
    "x = th.tensor(dataset.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf9b4fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test = split_train_test(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3882e099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([780, 9])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a009fdb",
   "metadata": {},
   "source": [
    "## Training the LogReg Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91ed7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(th.nn.Module): \n",
    "    def __init__(self,n_feat):\n",
    "        super(LogReg,self).__init__()\n",
    "        self.linear = th.nn.Linear(n_feat,1)\n",
    "    def forward(self,x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dd546ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LogReg(n_features)\n",
    "optim = torch.optim.SGD(model.parameters(),lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ce6a9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (epochs,model,x_train,y_train,optim,metric):\n",
    "    for epoch in range(1,epochs+1) :\n",
    "        optim.zero_grad()\n",
    "        out = model(x_train)\n",
    "        loss = metric(out,y_train)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"epoch : {epoch} loss : {loss}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "899f7708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 loss : 0.5855586528778076\n",
      "epoch : 2 loss : 0.5855574607849121\n",
      "epoch : 3 loss : 0.5855565071105957\n",
      "epoch : 4 loss : 0.5855557322502136\n",
      "epoch : 5 loss : 0.5855551362037659\n",
      "epoch : 6 loss : 0.5855545401573181\n",
      "epoch : 7 loss : 0.5855540633201599\n",
      "epoch : 8 loss : 0.5855537056922913\n",
      "epoch : 9 loss : 0.5855533480644226\n",
      "epoch : 10 loss : 0.5855530500411987\n",
      "epoch : 11 loss : 0.5855528712272644\n",
      "epoch : 12 loss : 0.5855526328086853\n",
      "epoch : 13 loss : 0.585552453994751\n",
      "epoch : 14 loss : 0.5855523347854614\n",
      "epoch : 15 loss : 0.5855522155761719\n",
      "epoch : 16 loss : 0.5855521559715271\n",
      "epoch : 17 loss : 0.5855520367622375\n",
      "epoch : 18 loss : 0.5855519771575928\n",
      "epoch : 19 loss : 0.5855518579483032\n",
      "epoch : 20 loss : 0.5855517983436584\n",
      "epoch : 21 loss : 0.5855517983436584\n",
      "epoch : 22 loss : 0.5855516791343689\n",
      "epoch : 23 loss : 0.5855516195297241\n",
      "epoch : 24 loss : 0.5855516195297241\n",
      "epoch : 25 loss : 0.5855515599250793\n",
      "epoch : 26 loss : 0.5855515599250793\n",
      "epoch : 27 loss : 0.5855515599250793\n",
      "epoch : 28 loss : 0.5855515003204346\n",
      "epoch : 29 loss : 0.5855515599250793\n",
      "epoch : 30 loss : 0.5855515003204346\n",
      "epoch : 31 loss : 0.5855515003204346\n",
      "epoch : 32 loss : 0.5855514407157898\n",
      "epoch : 33 loss : 0.5855515003204346\n",
      "epoch : 34 loss : 0.5855514407157898\n",
      "epoch : 35 loss : 0.5855515003204346\n",
      "epoch : 36 loss : 0.5855514407157898\n",
      "epoch : 37 loss : 0.585551381111145\n",
      "epoch : 38 loss : 0.5855514407157898\n",
      "epoch : 39 loss : 0.585551381111145\n",
      "epoch : 40 loss : 0.5855514407157898\n",
      "epoch : 41 loss : 0.5855514407157898\n",
      "epoch : 42 loss : 0.5855514407157898\n",
      "epoch : 43 loss : 0.5855514407157898\n",
      "epoch : 44 loss : 0.5855514407157898\n",
      "epoch : 45 loss : 0.585551381111145\n",
      "epoch : 46 loss : 0.5855514407157898\n",
      "epoch : 47 loss : 0.5855514407157898\n",
      "epoch : 48 loss : 0.585551381111145\n",
      "epoch : 49 loss : 0.585551381111145\n",
      "epoch : 50 loss : 0.5855513215065002\n"
     ]
    }
   ],
   "source": [
    "model = train(50,model,x_train,y_train,optim,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "04989815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,x_test,y_test): \n",
    "    out = model(x_test)\n",
    "    correct = torch.abs(y_test - out) < 0.5\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d9bb1e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy on plain data is : 0.6796407103538513\n"
     ]
    }
   ],
   "source": [
    "plain_accuracy = accuracy(model, x_test,y_test)\n",
    "print(f\"the accuracy on plain data is : {accuracy(model, x_test,y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439c9b5f",
   "metadata": {},
   "source": [
    "## Encrypted Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b6eaa99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HELogReg:\n",
    "    def __init__(self,torch_LogReg):\n",
    "        self.weight = torch_LogReg.weight.t().tolist()\n",
    "        self.bias = torch_LogReg.bias.t().tolist()\n",
    "    def forward(self,enc_x):\n",
    "        weight = np.array(self.weight).squeeze(1)\n",
    "        return enc_x.dot(weight) + self.bias\n",
    "\n",
    "    def __call__(self,*args,**keys): \n",
    "        return self.forward(*args,**keys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9ed6822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_model = HELogReg(model.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff172777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "541fd014",
   "metadata": {},
   "source": [
    "now we will create the context for the encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bb0817c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_scale = 20\n",
    "polynomial_modulus_degree = 8192\n",
    "coeff_mod_bit_sizes = [40,bit_scale,bit_scale,40]\n",
    "context = ts.context(ts.SCHEME_TYPE.CKKS,polynomial_modulus_degree, coeff_mod_bit_sizes  =coeff_mod_bit_sizes)\n",
    "context.global_scale = 2**bit_scale\n",
    "\n",
    "context.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c19b0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encrypting the test data \n",
    "enc_x_test = [ts.ckks_vector(context,x.tolist()) for x in x_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e65d21",
   "metadata": {},
   "source": [
    "We are not using the sigmoid fonction in the HE model for reducing the computation time, but we will use it in the evaluation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b938111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecnryption_evaluation(model,enc_x_test,y_test): \n",
    "    start = time()\n",
    "    correct = 0\n",
    "    for enc_x , y in zip(enc_x_test,y_test):\n",
    "        enc_out = model(enc_x)\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(y -out) < 0.5 : \n",
    "            # correct value\n",
    "            correct +=1\n",
    "    end = time()\n",
    "    print(f\"The evaluation process of {len(enc_x_test)} entries took : {end- start} seconds.\")\n",
    "    print(f\"The accuracy of ecrypted data is : {correct/len(enc_x_test)}\")\n",
    "    return correct / len(enc_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ed75bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation process of 334 entries took : 4.554850816726685 seconds.\n",
      "The accuracy of ecrypted data is : 0.5449101796407185\n",
      "Accuracy of the plain data is : 0.6796407103538513\n",
      "Accuracy on the encrypted data is : 0.5449101796407185\n"
     ]
    }
   ],
   "source": [
    "encrypted_acc = ecnryption_evaluation(he_model,enc_x_test,y_test)\n",
    "print(f\"Accuracy of the plain data is : {plain_accuracy}\")\n",
    "print(f\"Accuracy on the encrypted data is : {encrypted_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9c1da",
   "metadata": {},
   "source": [
    "we saw that there not big diffrence between the accucracy on the plain test set and the encrypted one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495e621",
   "metadata": {},
   "source": [
    "## Training and Encrypted LogReg Model on Encrypted Data\n",
    "\n",
    "our encrypted model will do both forward encrypted data and backpropagate to update the weights, and thus train encrypted logistic regression on encrypted data\n",
    "\n",
    "in this section we are going to define all the stuf from scratch, updated the parameters, defines the loss fonction (cross entropy), doing an approximation for the sigmoid fonction and trainng the encrypted model on an encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "8e3f447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLogReg:\n",
    "    def __init__(self,linear):\n",
    "        self.weight = linear.weight.data.tolist()[0]\n",
    "        self.bias = linear.bias.data.tolist()\n",
    "        # we need extra parameters for approving the gradient descnent and couting the itterations\n",
    "        # this parameters are calculated in the backward fonction for using them in the update_parameters fonctions\n",
    "        self._delta_weight = 0\n",
    "        self._delta_bias = 0\n",
    "        self._count = 0\n",
    "        # these params are the gradient accumulator \n",
    "    def forward(self,enc_x): \n",
    "        enc_out = enc_x.dot(self.weight) + self.bias \n",
    "        enc_out = EncryptedLogReg.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "\n",
    "    def backward(self,enc_x,enc_out, enc_y):\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        self._delta_weight += enc_x * out_minus_y \n",
    "        self._delta_bias += out_minus_y\n",
    "        self._count +=1 \n",
    "    def update_params(self): \n",
    "        if self._count ==0: \n",
    "            raise RuntimeError(\"You should at least run one forward iteration\")\n",
    "            \n",
    "        # update the weight and the bias using the gradient decent and the loss fonction of the cross entropy \n",
    "        # We use a small regularization term to keep the output\n",
    "        # of the linear layer in the range of the sigmoid approximation\n",
    "        \n",
    "        \n",
    "        #it's the formula for updating the parameters\n",
    "        self.weight -= self._delta_weight  * (1/self._count) + (self.weight* 0.005)\n",
    "        # the term : self.weight * 0.005 is for refularization\n",
    "        self.bias -= self._delta_bias * (1/self._count)\n",
    "        \n",
    "        #resetting the gradient accumulators\n",
    "        self._delta_bias = 0\n",
    "        self._delta_weight = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    @staticmethod \n",
    "    def sigmoid(enc_x):\n",
    "        #we will use the polynomial approximation of degree 3 \n",
    "        #which we have seen in the paper https://eprint.iacr.org/2018/462.pdf\n",
    "        # sigmoid = 0.5 + 0.197*x -0.004x^3\n",
    "        #the sigmoid approximation range is [-5,5], so if the inputes are in that range , the approximation work very well\n",
    "        \n",
    "        \n",
    "        return enc_x.polyval([0.5,0.197,0,-0.004])\n",
    "        #.polyval() it's a fonction that we give the parameter of the polynom and it will calculate for us the polynome based on the tensor\n",
    "    \n",
    "    def plain_accuracy(self,x_test,y_test): \n",
    "        # we will calculate the accuracy of the plain data to compare it with the accuracy on encrypted data\n",
    "        weight = torch.tensor(self.weight) \n",
    "        bias   = torch.tensor(self.bias)\n",
    "        out = x_test.matmul(weight) + bias \n",
    "        out  = torch.sigmoid(out)\n",
    "        out = out.reshape(-1,1)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()\n",
    "    \n",
    "    def encrypt(self,context):\n",
    "        self.weight = ts.ckks_vector(context,self.weight)\n",
    "        self.bias = ts.ckks_vector(context,self.bias)\n",
    "        \n",
    "    def decrypt(self): \n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self,*args,**keys): \n",
    "        return self.forward(*args,**keys)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2b252dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will define the encryption parameters \n",
    "bit_scale = 40\n",
    "poly_mod_degree = 16384\n",
    "coeff_mod_bit_sizes = [50,bit_scale,bit_scale,bit_scale,bit_scale,bit_scale,bit_scale,50]\n",
    "train_context = ts.context(ts.SCHEME_TYPE.CKKS,poly_mod_degree,coeff_mod_bit_sizes = coeff_mod_bit_sizes)\n",
    "train_context.global_scale = 2**bit_scale\n",
    "\n",
    "train_context.generate_galois_keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "37ec3d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation of encryption took 65.48992538452148 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "enc_x_train = [ts.ckks_vector(train_context,x.tolist()) for x  in x_train]\n",
    "enc_y_train = [ts.ckks_vector(train_context,y.tolist())for y in y_train]\n",
    "end = time()\n",
    "\n",
    "print(f\"The operation of encryption took {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed0618",
   "metadata": {},
   "source": [
    "since our sigmoid approximation is only good in the range $[-5,5]$, we want to have all its inputs in that range. In order to do this, we need to keep our logistic regression parameters as small as possible, so we apply regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "b06c2a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030038105323910713 0.3268715441226959\n",
      "Distribution on plain data : \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the encrypted data : \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_distribution  = lambda x , mean, varience : np.exp(-np.square((x-mean)/(2*var)) / np.sqrt(2 * np.pi * var))\n",
    "\n",
    "def plot_normal_dist(var,mean,rmin=-10,rmax=10): \n",
    "    x = np.arange(rmin,rmax,0.01)\n",
    "    y = normal_distribution(x,mean,var)\n",
    "    plt.plot(x,y)\n",
    "    \n",
    "\n",
    "#distribution on plain data\n",
    "model = LogReg(n_features)\n",
    "data = model.linear(x_test)\n",
    "mean,var = map(float,[data.mean(),data.std()**2])\n",
    "print(mean,var)\n",
    "plot_normal_dist(var,mean)\n",
    "print('Distribution on plain data : ')\n",
    "plt.show()\n",
    "\n",
    "#distribution on encrypted data \n",
    "enc_eval_log_reg = EncryptedLogReg(model.linear)\n",
    "#encrypting the weight and the bias \n",
    "enc_eval_log_reg.encrypt(train_context)\n",
    "\n",
    "weight = enc_eval_log_reg.weight\n",
    "bias = enc_eval_log_reg.bias\n",
    "data = []\n",
    "for enc_x in enc_x_train: \n",
    "    enc_out = enc_x.dot(weight) + bias\n",
    "    data.append(enc_out.decrypt())\n",
    "    \n",
    "data = torch.tensor(data)\n",
    "mean , var = map(float,[data.mean(),data.std()**2])\n",
    "plot_normal_dist(var,mean)\n",
    "print(\"Distribution of the encrypted data : \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e177bd",
   "metadata": {},
   "source": [
    "we see that the most of the data are in the range of [-5,5] so the approximation of the sigmoid will work fine \n",
    "\n",
    "Now it's time to train the model on encrypted data : \n",
    "        \n",
    "    and for that we will create the ecnrypted evaluation model and encrypt the weight and the bias \n",
    "    after that we will go into our encrypted data (enc_x_train & enc_y_test) and give each encrypted vector to the model using the forward() and the backward() fonctions to update the delta_weight and delta_bias\n",
    "    in the end of every epoch we will update the params and calculate the accuracy \n",
    "    \n",
    "    We can see that we decrypt the weights and re-encrypt them again after every epoch, this is necessary since after    updating the weights at the end of the epoch, we can no longer use them to perform enough multiplications, so we need to get them back to the initial ciphertext level. \n",
    "    \n",
    "    In a real scenario, this would translate to sending the weights back to the secret-key holder for decryption and re-encryption. In that case, it will result in just a few Kilobytes of communication per epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "91e318fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_train(context,enc_model,enc_x_train,enc_y_train,x_test,y_test,epochs):\n",
    "    accuracy = enc_model.plain_accuracy(x_test,y_test)\n",
    "    print(f\"The accuracy in the epoch 0 : {accuracy}\")\n",
    "    times = []\n",
    "    for epoch in range(1,epochs+1): \n",
    "        print(f\"Epoch : {epoch} started\")\n",
    "        #encrypting the weight and the bias\n",
    "        enc_model.encrypt(context)\n",
    "        start_time = time()\n",
    "        for enc_x,enc_y in zip(enc_x_train,enc_y_train): \n",
    "            enc_out = enc_model.forward(enc_x)\n",
    "            enc_model.backward(enc_x,enc_out,enc_y)\n",
    "        #in the end of the tarining for each epoch, we update the params\n",
    "        enc_model.update_params()\n",
    "        end_time = time()\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "        #we will decrypt the weights \n",
    "        enc_model.decrypt()\n",
    "        accuracy = enc_model.plain_accuracy(x_test,y_test)\n",
    "        print(f\"Accuracy at epoch {epoch} is : {accuracy}\")\n",
    "        \n",
    "    return model,times,accuracy\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "48bb2efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in the epoch 0 : 0.5329341292381287\n",
      "Epoch : 1 started\n",
      "[0.2743434872508937, 0.3919851277753926, 0.26577781108898924, 0.18104249822245477, -0.07827368080198978, 0.033732655210451074, -0.040768814274010336, 0.10627981645340301, 0.15409583564150137]\n",
      "Accuracy at epoch 1 is : 0.6257485151290894\n",
      "Epoch : 2 started\n",
      "[0.2638650444584193, 0.484294155819898, 0.2519811771501451, 0.1799487306394393, 0.05031786655143268, 0.09898348234881024, 0.10596657834571675, 0.10922168854950033, 0.19239415218460648]\n",
      "Accuracy at epoch 2 is : 0.667664647102356\n",
      "Epoch : 3 started\n",
      "[0.259662451138717, 0.536869103660764, 0.24809780290485292, 0.17716489671945124, 0.1252830573979135, 0.13830150808065977, 0.1941114514263676, 0.10290455187156458, 0.2140530369721437]\n",
      "Accuracy at epoch 3 is : 0.667664647102356\n",
      "Epoch : 4 started\n",
      "[0.2586526518994851, 0.5676534791690874, 0.24945128798624278, 0.173925311282206, 0.1699365571794293, 0.16315737609551306, 0.24948669476978869, 0.09326218022464601, 0.2277328457488124]\n",
      "Accuracy at epoch 4 is : 0.682634711265564\n",
      "Epoch : 5 started\n",
      "[0.25909515111685866, 0.5860268723225522, 0.2533520041637206, 0.17068363592001767, 0.19684535960982627, 0.1795502124225719, 0.28577215920399474, 0.08289070029418283, 0.2372474622904646]\n",
      "Accuracy at epoch 5 is : 0.682634711265564\n"
     ]
    }
   ],
   "source": [
    "encrypted_eval_model = EncryptedLogReg(LogReg(n_features).linear)\n",
    "EPOCHS = 5\n",
    "_,times,last_accuracy = encrypted_train(train_context,encrypted_eval_model,enc_x_train,enc_y_train,x_test,y_test,EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cac72",
   "metadata": {},
   "source": [
    "We see that the accuracy on plain_text is increasing from epoch to another so we get a result after tarining the encrypted Model on encrypted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "53d9bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation operation took : \n",
      "\t1028 seconds\n",
      "The average time per epoch is : \n",
      "\t205.6 seconds\n",
      "The last accuracy is : \n",
      "\t0.682634711265564\n",
      "The difference accuracy is : \n",
      "\t-0.0029940009117126465\n"
     ]
    }
   ],
   "source": [
    "print(f\"The evaluation operation took : \\n\\t{int(sum(times))} seconds\")\n",
    "print(f\"The average time per epoch is : \\n\\t{int(sum(times)) /len(times)} seconds\")\n",
    "print(f\"The last accuracy is : \\n\\t{last_accuracy}\")\n",
    "print(f\"The Accaccuracy on the plain text : {plain_accuracy})\n",
    "print(f\"The difference accuracy is : \\n\\t{plain_accuracy - last_accuracy }\")\n",
    "if (plain_accuracy - last_accuracy ) < 0 :\n",
    "    print(\"Wooow, We got better accuracy when training on encrypted data !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375553cf",
   "metadata": {},
   "source": [
    "now we are going to train the same encrypted model on more epochs and see the evolution of the accuracy on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "8d3c4fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in the epoch 0 : 0.682634711265564\n",
      "Epoch : 1 started\n",
      "[0.26007704301940016, 0.5970840970462332, 0.2583154707032393, 0.16762159609024263, 0.21303398909044136, 0.19074457648346482, 0.31046554342378296, 0.07291962848978555, 0.24437927805554954]\n",
      "Accuracy at epoch 1 is : 0.6856287717819214\n",
      "Epoch : 2 started\n",
      "[0.26113917155911015, 0.6037230911984536, 0.2635359936367491, 0.16481320465339996, 0.22260036498004843, 0.19861392693325242, 0.3278767993096683, 0.06381794317297329, 0.25003150625224396]\n",
      "Accuracy at epoch 2 is : 0.6796407103538513\n",
      "Epoch : 3 started\n",
      "[0.26206759306652805, 0.6076535059972915, 0.268590113698291, 0.16228356374687686, 0.22801690644564152, 0.2042841123748781, 0.34058479490426635, 0.055743506481025856, 0.25469772014295416]\n",
      "Accuracy at epoch 3 is : 0.682634711265564\n",
      "Epoch : 4 started\n",
      "[0.2627797083388491, 0.6099104419009286, 0.2732710257900994, 0.1600331086776492, 0.23081184849607878, 0.2084573401163604, 0.35018067406110154, 0.04870409135676697, 0.2586657580648214]\n",
      "Accuracy at epoch 4 is : 0.682634711265564\n",
      "Epoch : 5 started\n",
      "[0.26326137246924636, 0.6111316426128128, 0.27749413893774677, 0.1580492084298876, 0.23194601417769758, 0.21158510526626562, 0.3576694005705716, 0.04263636221098978, 0.26211313371998035]\n",
      "Accuracy at epoch 5 is : 0.682634711265564\n",
      "Epoch : 6 started\n",
      "[0.26353180075633276, 0.6117144396414741, 0.2812426323583879, 0.1563124532024637, 0.2320307915231613, 0.21396544567348452, 0.36369769316467326, 0.03744642638953108, 0.2651548468534715]\n",
      "Accuracy at epoch 6 is : 0.682634711265564\n",
      "Epoch : 7 started\n",
      "[0.2636241972580842, 0.6119079789074584, 0.28453547263838597, 0.15480032260233256, 0.2314585263089977, 0.215799837513325, 0.36868850728830305, 0.03303099947740827, 0.26786882863977896]\n",
      "Accuracy at epoch 7 is : 0.682634711265564\n",
      "Epoch : 8 started\n",
      "[0.2635752436473389, 0.6118689366859277, 0.2874089995179679, 0.15348948210035598, 0.2304826185450769, 0.2172275618247425, 0.37292272479619837, 0.02928851783413082, 0.2703101366761632]\n",
      "Accuracy at epoch 8 is : 0.682634711265564\n",
      "Epoch : 9 started\n",
      "[0.26341976513162335, 0.6116957782566692, 0.2899063103614512, 0.15235709813702, 0.22926737508290915, 0.21834706260609563, 0.3765897953274352, 0.026124606292346836, 0.27251925524295006]\n",
      "Accuracy at epoch 9 is : 0.682634711265564\n",
      "Epoch : 10 started\n",
      "[0.26318833180886225, 0.6114501403306323, 0.29207138162659996, 0.15138167098822122, 0.22791965534536987, 0.21922942795578498, 0.379819679328277, 0.023454459802490946, 0.2745270599678255]\n",
      "Accuracy at epoch 10 is : 0.682634711265564\n",
      "Epoch : 11 started\n",
      "[0.26290640462190606, 0.6111702832555563, 0.29394597910623144, 0.1505434256961907, 0.22650895314716873, 0.21992701015232036, 0.38270317130171444, 0.02120349938421598, 0.2763579080923272]\n",
      "Accuracy at epoch 11 is : 0.682634711265564\n",
      "Epoch : 12 started\n",
      "[0.26259447143164416, 0.6108796109564315, 0.2955682054060542, 0.14982450756494584, 0.2250804153919299, 0.22047913614133174, 0.3853050223675942, 0.019307058031590885, 0.27803158179541065]\n",
      "Accuracy at epoch 12 is : 0.682634711265564\n",
      "Epoch : 13 started\n",
      "[0.2622684550671473, 0.6105920935818686, 0.29697197649254287, 0.1492089793352301, 0.22366316401486772, 0.22091585497231558, 0.38767244998901906, 0.017709692607262295, 0.27956457669540874]\n",
      "Accuracy at epoch 13 is : 0.682634711265564\n",
      "Epoch : 14 started\n",
      "[0.26194040758252546, 0.6103157403034738, 0.29818704130696894, 0.1486827637660425, 0.2222758005822258, 0.2212604348890848, 0.389840691492531, 0.016364176916249973, 0.28097089416393356]\n",
      "Accuracy at epoch 14 is : 0.682634711265564\n",
      "Epoch : 15 started\n",
      "[0.26161913344008914, 0.6100548008966178, 0.2992392528056777, 0.14823350277021638, 0.22092992562583386, 0.22153118249063014, 0.39183670186760533, 0.015230467989562402, 0.282262620557619]\n",
      "Accuracy at epoch 15 is : 0.682634711265564\n",
      "Epoch : 16 started\n",
      "[0.26131084567103346, 0.6098112112345577, 0.3001508951805768, 0.14785041772930468, 0.21963247695916144, 0.22174263050118892, 0.3936815961425313, 0.014274774744019392, 0.2834503489678599]\n",
      "Accuracy at epoch 16 is : 0.682634711265564\n",
      "Epoch : 17 started\n",
      "[0.261019694332138, 0.6095854457293471, 0.3009411708574781, 0.14752414441554845, 0.2183873310381064, 0.22190638545815547, 0.3953923045392915, 0.013468662970282791, 0.2845434300999567]\n",
      "Accuracy at epoch 17 is : 0.682634711265564\n",
      "Epoch : 18 started\n",
      "[0.260748235477277, 0.6093771525123174, 0.30162654695820323, 0.14724658331104504, 0.21719627714185855, 0.22203179619936347, 0.39698269143983855, 0.012788237506374561, 0.2855501873662795]\n",
      "Accuracy at epoch 18 is : 0.6796407103538513\n",
      "Epoch : 19 started\n",
      "[0.26049781626457746, 0.6091854785055307, 0.302221175750427, 0.14701071243446553, 0.2160597130661204, 0.22212643002086818, 0.3984643332193747, 0.012213465978563931, 0.2864780890585965]\n",
      "Accuracy at epoch 19 is : 0.6796407103538513\n",
      "Epoch : 20 started\n",
      "[0.2602689122515459, 0.6090093299457568, 0.30273720651768127, 0.14681050938563564, 0.21497714991088707, 0.22219642184230998, 0.3998470689165795, 0.011727530777551842, 0.28733382350258196]\n",
      "Accuracy at epoch 20 is : 0.6796407103538513\n"
     ]
    }
   ],
   "source": [
    "_,times,last_accuracy = encrypted_train(train_context,encrypted_eval_model,enc_x_train,enc_y_train,x_test,y_test,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "d3f7da5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The evaluation operation took : \n",
      "\t3759 seconds\n",
      "The average time per epoch is : \n",
      "\t187.95 seconds\n",
      "The last accuracy is : \n",
      "\t0.6796407103538513\n",
      "The Accaccuracy on the plain text : 0.6796407103538513\n",
      "The difference accuracy is : \n",
      "\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The evaluation operation took : \\n\\t{int(sum(times))} seconds\")\n",
    "print(f\"The average time per epoch is : \\n\\t{int(sum(times)) /len(times)} seconds\")\n",
    "print(f\"The last accuracy is : \\n\\t{last_accuracy}\")\n",
    "print(f\"The Accaccuracy on the plain text : {plain_accuracy}\")\n",
    "print(f\"The difference accuracy is : \\n\\t{plain_accuracy - last_accuracy }\")\n",
    "if (plain_accuracy - last_accuracy ) < 0 :\n",
    "    print(\"Wooow, We got better accuracy when training on encrypted data !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b1dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
